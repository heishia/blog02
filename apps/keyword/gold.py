import hashlib
import hmac
import time
import requests
import urllib.request
import urllib.parse
import json
from typing import List, Dict
import yaml
import pandas as pd
from datetime import datetime
import os

# í…ŒìŠ¤íŠ¸ìš© í‚¤ì›Œë“œ (ë””ë²„ê¹… ì‹œ ì‰½ê²Œ ìˆ˜ì • ê°€ëŠ¥)
TEST_KEYWORDS = [
    "ìš´ë¹¨ì¡´ë§ê²œ", "ê²Œì„ì•„ì´í…œ", "RPGì¥ë¹„", "ì˜¨ë¼ì¸ê²Œì„", "ëª¨ë°”ì¼ê²Œì„",  # 1-5
    "ì•¡ì…˜ê²Œì„", "ì‹œë®¬ë ˆì´ì…˜", "ì „ëµê²Œì„", "ë¸”ë¡œê·¸íŒ", "ì¼ê¸°ì“°ê¸°"  # 6-10 (ë” ì‘ì€ ê²€ìƒ‰ëŸ‰ í‚¤ì›Œë“œ ì¶”ê°€)
]

# í‚¤ì›Œë“œ ì£¼ì œ (ì—‘ì…€ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©)
KEYWORD_SUBJECT = "ê²Œì„"

# ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ëª¨ë“œ ì„¤ì •
# MODE: "BASIC" (ê¸°ë³¸ëª¨ë“œ) ë˜ëŠ” "AUTO" (ìë™ëª¨ë“œ)
MODE = "AUTO"

# ê¸°ë³¸ëª¨ë“œì¼ ë•Œë§Œ ì‚¬ìš©ë˜ëŠ” ìŠ¤í…Œì´ì§€ ë ˆë²¨ (1-5ë‹¨ê³„ ì¤‘ ì„ íƒ)
BLOG_STAGES = 4

class NaverAdsClient:
    """ë„¤ì´ë²„ ê´‘ê³  API í´ë¼ì´ì–¸íŠ¸ - ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ì „ìš©"""
    
    def __init__(self, config_path: str = "config/base.yaml"):
        self.config = self._load_config(config_path)
        self.base_url = "https://api.searchad.naver.com"  # ì˜¬ë°”ë¥¸ API URL
        self.customer_id = self.config['credentials']['naver_ads']['customer_id']
        self.api_key = self.config['credentials']['naver_ads']['api_key']
        self.secret_key = self.config['credentials']['naver_ads']['secret_key']
        
        # ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì„¤ì • ë¡œë“œ
        self.blog_stages_config = self._load_blog_stages_config()
    
    def _load_config(self, config_path: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def _load_blog_stages_config(self) -> Dict:
        """ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì„¤ì • ë¡œë“œ"""
        try:
            with open("config/keyword.yaml", 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"âš ï¸ ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def _generate_signature(self, timestamp: str, method: str, uri: str) -> str:
        """ì„œëª… ìƒì„±"""
        # URIì—ì„œ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì œê±° (ì„œëª…ìš©)
        clean_uri = uri.split('?')[0] if '?' in uri else uri
        message = f"{timestamp}.{method}.{clean_uri}"
        
        signature = hmac.new(
            self.secret_key.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).digest()
        
        # base64 ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½ (ë„¤ì´ë²„ API ìš”êµ¬ì‚¬í•­)
        import base64
        signature_b64 = base64.b64encode(signature).decode('utf-8')
        
        return signature_b64
    
    def _get_headers(self, method: str, uri: str) -> Dict[str, str]:
        """API ìš”ì²­ í—¤ë” ìƒì„±"""
        timestamp = str(int(time.time() * 1000))
        signature = self._generate_signature(timestamp, method, uri)
        
        headers = {
            'X-Timestamp': timestamp,
            'X-API-KEY': self.api_key,
            'X-Customer': str(self.customer_id),
            'X-Signature': signature,
            'Content-Type': 'application/json'
        }
        
        return headers
    
    def _get_search_volume_batch(self, keywords: List[str]) -> Dict[str, Dict[str, str]]:
        """
        í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (5ê°œ ì´í•˜ ë°°ì¹˜)
        
        Args:
            keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 5ê°œ)
        
        Returns:
            í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ ì •ë³´
        """
        if len(keywords) > 5:
            raise ValueError("ë°°ì¹˜ë‹¹ í‚¤ì›Œë“œëŠ” ìµœëŒ€ 5ê°œê¹Œì§€ ì…ë ¥ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        
        # í‚¤ì›Œë“œì—ì„œ ê³µë°± ì œê±° ë° ì •ë¦¬
        cleaned_keywords = [keyword.strip().replace(' ', '') for keyword in keywords]
        
        # API ì—”ë“œí¬ì¸íŠ¸
        uri = "/keywordstool"
        params = {
            'hintKeywords': ','.join(cleaned_keywords),
            'showDetail': 0
        }
        
        query_string = '&'.join([f"{k}={v}" for k, v in params.items()])
        full_uri = f"{uri}?{query_string}"
        
        headers = self._get_headers('GET', full_uri)
        
        try:
            response = requests.get(
                f"{self.base_url}{full_uri}",
                headers=headers
            )
            
            response.raise_for_status()
            
            result = response.json()
            
            # ê²€ìƒ‰ëŸ‰ë§Œ ì¶”ì¶œ
            keyword_stats = {}
            
            # ì‘ë‹µì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if isinstance(result, list):
                for item in result:
                    if isinstance(item, dict):
                        keyword = item.get('relKeyword', '')
                        if keyword:
                            keyword_stats[keyword] = {
                                'pc_search_volume': item.get('monthlyPcQcCnt', '0'),
                                'mobile_search_volume': item.get('monthlyMobileQcCnt', '0')
                            }
            elif isinstance(result, dict) and 'keywordList' in result:
                # keywordList í˜•íƒœì˜ ì‘ë‹µ ì²˜ë¦¬
                for item in result['keywordList']:
                    if isinstance(item, dict):
                        keyword = item.get('relKeyword', '')
                        if keyword:
                            keyword_stats[keyword] = {
                                'pc_search_volume': item.get('monthlyPcQcCnt', '0'),
                                'mobile_search_volume': item.get('monthlyMobileQcCnt', '0')
                            }
            else:
                print(f"âš ï¸ ì˜ˆìƒê³¼ ë‹¤ë¥¸ ì‘ë‹µ í˜•ì‹: {type(result)}")
                return {}
            
            return keyword_stats
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
        except Exception as e:
            raise Exception(f"ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def get_search_volume(self, keywords: List[str] = None) -> Dict[str, Dict[str, str]]:
        """
        í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ (ìë™ ë°°ì¹˜ ì²˜ë¦¬)
        
        Args:
            keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ TEST_KEYWORDS ì‚¬ìš©)
        
        Returns:
            í‚¤ì›Œë“œë³„ ê²€ìƒ‰ëŸ‰ ì •ë³´
        """
        if keywords is None:
            keywords = TEST_KEYWORDS
            
        # 5ê°œì”© ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        batches = [keywords[i:i+5] for i in range(0, len(keywords), 5)]
        print(f"ğŸ“Š ì´ {len(keywords)}ê°œ í‚¤ì›Œë“œë¥¼ {len(batches)}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        all_results = {}
        
        for i, batch in enumerate(batches, 1):
            print(f"ğŸ”„ ë°°ì¹˜ {i}/{len(batches)} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ í‚¤ì›Œë“œ)")
            
            try:
                batch_result = self._get_search_volume_batch(batch)
                all_results.update(batch_result)
                
                # API í˜¸ì¶œ ê°„ê²© (ê³¼ë„í•œ ìš”ì²­ ë°©ì§€)
                if i < len(batches):
                    print("â±ï¸ API í˜¸ì¶œ ê°„ê²© ëŒ€ê¸° ì¤‘...")
                    time.sleep(1)
                    
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"âœ… ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: {len(all_results)}ê°œ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ")
        return all_results
    
    def get_keyword_stage(self, doc_count: int, total_search: int) -> int:
        """
        í‚¤ì›Œë“œì˜ ìŠ¤í…Œì´ì§€ ë‹¨ê³„ í™•ì¸
        
        Args:
            doc_count: ë¬¸ì„œìˆ˜
            total_search: ì´ ê²€ìƒ‰ëŸ‰
        
        Returns:
            í•´ë‹¹í•˜ëŠ” ìŠ¤í…Œì´ì§€ ë‹¨ê³„ (1-5, í•´ë‹¹ ì—†ìœ¼ë©´ 0)
        """
        if not self.blog_stages_config or 'blog_stages' not in self.blog_stages_config:
            return 0
        
        # 1ë‹¨ê³„ë¶€í„° 5ë‹¨ê³„ê¹Œì§€ ìˆœì„œëŒ€ë¡œ í™•ì¸
        for stage_num in range(1, 6):
            stage_key = str(stage_num)
            if stage_key in self.blog_stages_config['blog_stages']:
                stage_config = self.blog_stages_config['blog_stages'][stage_key]
                d_max = stage_config.get('D_max', float('inf'))
                s_min = stage_config.get('S_min', 0)
                s_max = stage_config.get('S_max', float('inf'))
                
                # ê¸°ë³¸ ì¡°ê±´ í™•ì¸
                if (doc_count <= d_max and s_min <= total_search <= s_max):
                    # 2~5ë‹¨ê³„ì—ì„œëŠ” ì¶”ê°€ ì¡°ê±´: ê²€ìƒ‰ëŸ‰ >= ë¬¸ì„œìˆ˜
                    if stage_num == 1:
                        # 1ë‹¨ê³„ëŠ” ê¸°ë³¸ ì¡°ê±´ë§Œ í™•ì¸
                        return stage_num
                    else:
                        # 2~5ë‹¨ê³„ëŠ” ê²€ìƒ‰ëŸ‰ì´ ë¬¸ì„œìˆ˜ë³´ë‹¤ ë†’ê±°ë‚˜ ê°™ì•„ì•¼ í•¨
                        if total_search >= doc_count:
                            return stage_num
                        # ì¡°ê±´ì— ë§ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ë‹¨ê³„ í™•ì¸
                        continue
        
        return 0  # ì–´ë–¤ ë‹¨ê³„ì—ë„ í•´ë‹¹í•˜ì§€ ì•ŠìŒ

    def filter_keywords_by_stage(self, analysis_result: Dict[str, Dict[str, any]], stage: int = None) -> Dict[str, Dict[str, any]]:
        """
        ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì¡°ê±´ì— ë§ëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
        
        Args:
            analysis_result: í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
            stage: ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ (Noneì´ë©´ BLOG_STAGES ìƒìˆ˜ ì‚¬ìš©)
        
        Returns:
            í•„í„°ë§ëœ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ (ìŠ¤í…Œì´ì§€ ì •ë³´ í¬í•¨)
        """
        if stage is None:
            stage = BLOG_STAGES
        
        if not self.blog_stages_config or 'blog_stages' not in self.blog_stages_config:
            print("âš ï¸ ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return analysis_result
        
        stage_key = str(stage)
        if stage_key not in self.blog_stages_config['blog_stages']:
            print(f"âš ï¸ ìŠ¤í…Œì´ì§€ {stage} ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return analysis_result
        
        stage_config = self.blog_stages_config['blog_stages'][stage_key]
        d_max = stage_config.get('D_max', float('inf'))  # ë¬¸ì„œìˆ˜ ìµœëŒ€ê°’
        s_min = stage_config.get('S_min', 0)            # ê²€ìƒ‰ëŸ‰ ìµœì†Œê°’
        s_max = stage_config.get('S_max', float('inf')) # ê²€ìƒ‰ëŸ‰ ìµœëŒ€ê°’
        
        print(f"ğŸ” ìŠ¤í…Œì´ì§€ {stage} í•„í„°ë§ ì¡°ê±´:")
        print(f"   ğŸ“„ ë¬¸ì„œìˆ˜: â‰¤ {d_max}")
        print(f"   ğŸ” ê²€ìƒ‰ëŸ‰: {s_min} ~ {s_max}")
        
        filtered_result = {}
        total_count = len(analysis_result)
        passed_count = 0
        
        for keyword, stats in analysis_result.items():
            doc_count = stats['blog_count']
            total_search = stats['total_search_volume']
            
            # í‚¤ì›Œë“œê°€ ì†í•˜ëŠ” ìŠ¤í…Œì´ì§€ í™•ì¸
            keyword_stage = self.get_keyword_stage(doc_count, total_search)
            
            # í˜„ì¬ ì„¤ì •ëœ ìŠ¤í…Œì´ì§€ ì¡°ê±´ì— ë§ëŠ”ì§€ í™•ì¸
            if (doc_count <= d_max and 
                s_min <= total_search <= s_max):
                # ìŠ¤í…Œì´ì§€ ì •ë³´ ì¶”ê°€
                stats['stage'] = keyword_stage
                filtered_result[keyword] = stats
                passed_count += 1
        
        print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {total_count}ê°œ ì¤‘ {passed_count}ê°œ í‚¤ì›Œë“œ í†µê³¼")
        return filtered_result
    
    def filter_keywords_auto_mode(self, analysis_result: Dict[str, Dict[str, any]]) -> Dict[str, Dict[str, any]]:
        """
        ìë™ëª¨ë“œ: 1-5ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ ë¶„ë¥˜í•˜ì—¬ ì €ì¥ (í•´ë‹¹ì—†ìŒ ì œì™¸)
        
        Args:
            analysis_result: í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
        
        Returns:
            1-5ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ í¬í•¨ëœ ë¶„ì„ ê²°ê³¼ (ìŠ¤í…Œì´ì§€ ì •ë³´ í¬í•¨)
        """
        if not self.blog_stages_config or 'blog_stages' not in self.blog_stages_config:
            print("âš ï¸ ë¸”ë¡œê·¸ ìŠ¤í…Œì´ì§€ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return analysis_result
        
        print("ğŸ” ìë™ëª¨ë“œ: 1-5ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ ë¶„ë¥˜í•˜ì—¬ ì €ì¥...")
        
        auto_result = {}
        total_count = len(analysis_result)
        stage_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 0: 0}  # 0ì€ í•´ë‹¹ì—†ìŒ
        
        for keyword, stats in analysis_result.items():
            doc_count = stats['blog_count']
            total_search = stats['total_search_volume']
            
            # í‚¤ì›Œë“œê°€ ì†í•˜ëŠ” ìŠ¤í…Œì´ì§€ í™•ì¸
            keyword_stage = self.get_keyword_stage(doc_count, total_search)
            
            # ë‹¨ê³„ë³„ ì¹´ìš´íŠ¸ (ì „ì²´ í†µê³„ìš©)
            stage_counts[keyword_stage] += 1
            
            # 1-5ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œë§Œ ì €ì¥ (0ë‹¨ê³„ ì œì™¸)
            if keyword_stage > 0:
                stats['stage'] = keyword_stage
                auto_result[keyword] = stats
        
        print("ğŸ“Š ìë™ ë¶„ë¥˜ ê²°ê³¼:")
        for stage in range(1, 6):
            count = stage_counts[stage]
            if count > 0:
                print(f"   {stage}ë‹¨ê³„: {count}ê°œ")
        
        no_stage_count = stage_counts[0]
        if no_stage_count > 0:
            print(f"   í•´ë‹¹ì—†ìŒ: {no_stage_count}ê°œ (ì—‘ì…€ ì €ì¥ ì œì™¸)")
        
        saved_count = sum(stage_counts[i] for i in range(1, 6))
        print(f"âœ… ìë™ ë¶„ë¥˜ ì™„ë£Œ: ì´ {total_count}ê°œ ì¤‘ {saved_count}ê°œ í‚¤ì›Œë“œ ì €ì¥")
        return auto_result
    
    def search_keywords(self, keywords: List[str] = None) -> Dict[str, Dict[str, str]]:
        """get_search_volumeì˜ ë³„ì¹­"""
        return self.get_search_volume(keywords)
    
    def get_blog_count(self, keyword: str) -> int:
        """
        í‚¤ì›Œë“œì˜ ë¸”ë¡œê·¸ ë¬¸ì„œëŸ‰ ì¡°íšŒ
        
        Args:
            keyword: ê²€ìƒ‰í•  í‚¤ì›Œë“œ
        
        Returns:
            ë¸”ë¡œê·¸ ë¬¸ì„œ ê°œìˆ˜
        """
        try:
            # ë„¤ì´ë²„ ê²€ìƒ‰ API ì„¤ì •
            client_id = self.config['credentials']['naver_openapi']['client_id']
            client_secret = self.config['credentials']['naver_openapi']['client_secret']
            
            # URL ì¸ì½”ë”©
            enc_text = urllib.parse.quote(keyword)
            url = f"https://openapi.naver.com/v1/search/blog?query={enc_text}&display=1&start=1"
            
            # ìš”ì²­ ìƒì„±
            request = urllib.request.Request(url)
            request.add_header("X-Naver-Client-Id", client_id)
            request.add_header("X-Naver-Client-Secret", client_secret)
            
            # API í˜¸ì¶œ
            response = urllib.request.urlopen(request)
            rescode = response.getcode()
            
            if rescode == 200:
                response_body = response.read()
                result = json.loads(response_body.decode('utf-8'))
                
                # ì´ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ ë°˜í™˜
                total_count = result.get('total', 0)
                return total_count
            else:
                print(f"âŒ ë¸”ë¡œê·¸ API ì˜¤ë¥˜ ì½”ë“œ: {rescode}")
                return 0
                
        except Exception as e:
            print(f"âŒ ë¸”ë¡œê·¸ ë¬¸ì„œëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_keyword_analysis(self, keywords: List[str] = None) -> Dict[str, Dict[str, any]]:
        """
        í‚¤ì›Œë“œ í†µí•© ë¶„ì„ (ê²€ìƒ‰ëŸ‰ + ë¬¸ì„œëŸ‰ + ê²½ìŸë„)
        
        Args:
            keywords: ë¶„ì„í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ TEST_KEYWORDS ì‚¬ìš©)
        
        Returns:
            í‚¤ì›Œë“œë³„ í†µí•© ë¶„ì„ ê²°ê³¼
        """
        if keywords is None:
            keywords = TEST_KEYWORDS
        
        # ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        search_volume_result = self.get_search_volume(keywords)
        
        # í†µí•© ê²°ê³¼ ìƒì„±
        analysis_result = {}
        
        # í‚¤ì›Œë“œ ì •ë¦¬ (ê³µë°± ì œê±°)
        cleaned_keywords = [keyword.strip().replace(' ', '') for keyword in keywords]
        
        for i, original_keyword in enumerate(keywords):
            cleaned_keyword = cleaned_keywords[i]
            if cleaned_keyword in search_volume_result:
                # ë¸”ë¡œê·¸ ë¬¸ì„œëŸ‰ ì¡°íšŒ (ì›ë³¸ í‚¤ì›Œë“œë¡œ)
                blog_count = self.get_blog_count(original_keyword)
                
                # PCì™€ ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰ì„ ì •ìˆ˜ë¡œ ë³€í™˜ (< 10 ê°™ì€ ë¬¸ìì—´ ì²˜ë¦¬)
                def parse_volume(volume_str):
                    if isinstance(volume_str, int):
                        return volume_str
                    if isinstance(volume_str, str):
                        if volume_str.startswith('<'):
                            return 5  # "< 10"ì¸ ê²½ìš° 5ë¡œ ì²˜ë¦¬
                        try:
                            return int(volume_str)
                        except:
                            return 0
                    return 0
                
                pc_volume = parse_volume(search_volume_result[cleaned_keyword]['pc_search_volume'])
                mobile_volume = parse_volume(search_volume_result[cleaned_keyword]['mobile_search_volume'])
                
                # ì´ê²€ìƒ‰ëŸ‰ ê³„ì‚°
                total_search_volume = pc_volume + mobile_volume
                
                # ê²½ìŸë„ ê³„ì‚° (ë¬¸ì„œìˆ˜ Ã· ì´ê²€ìƒ‰ëŸ‰)
                competition_ratio = round(blog_count / total_search_volume, 3) if total_search_volume > 0 else 0
                
                analysis_result[original_keyword] = {
                    'pc_search_volume': pc_volume,
                    'mobile_search_volume': mobile_volume,
                    'total_search_volume': total_search_volume,
                    'blog_count': blog_count,
                    'competition_ratio': competition_ratio
                }
        
        return analysis_result
    
    def save_to_excel(self, analysis_result: Dict[str, Dict[str, any]], filename: str = None) -> str:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ (ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€/ì—…ë°ì´íŠ¸)
        
        Args:
            analysis_result: í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
            filename: ì €ì¥í•  íŒŒì¼ëª… (Noneì´ë©´ KEYWORD_SUBJECT ì‚¬ìš©)
        
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        try:
            # ì €ì¥ í´ë” ìƒì„±
            save_directory = "static/gold_keyword"
            os.makedirs(save_directory, exist_ok=True)
            
            # íŒŒì¼ëª… ì„¤ì •
            if filename is None:
                filename = f"{KEYWORD_SUBJECT}.xlsx"
            
            # ì „ì²´ íŒŒì¼ ê²½ë¡œ ì„¤ì •
            filepath = os.path.join(save_directory, filename)
            
            # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
            existing_df = None
            if os.path.exists(filepath):
                try:
                    existing_df = pd.read_excel(filepath)
                    print(f"ğŸ“ ê¸°ì¡´ íŒŒì¼ ë¡œë“œ: {len(existing_df)}ê°œ í‚¤ì›Œë“œ")
                except Exception as e:
                    print(f"âš ï¸ ê¸°ì¡´ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # ìƒˆë¡œìš´ ë°ì´í„° ì¤€ë¹„
            new_data = []
            for keyword, stats in analysis_result.items():
                new_data.append({
                    'í‚¤ì›Œë“œ': keyword,
                    'PC ê²€ìƒ‰ëŸ‰': stats['pc_search_volume'],
                    'ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰': stats['mobile_search_volume'],
                    'ì´ê²€ìƒ‰ëŸ‰': stats['total_search_volume'],
                    'ë¬¸ì„œëŸ‰': stats['blog_count'],
                    'ê²½ìŸë„': stats['competition_ratio'],
                    'ë‹¨ê³„': stats.get('stage', 0)  # ìŠ¤í…Œì´ì§€ ì •ë³´ ì¶”ê°€
                })
            
            new_df = pd.DataFrame(new_data)
            
            if existing_df is not None:
                # ìë™ëª¨ë“œì—ì„œ ê¸°ì¡´ ë°ì´í„°ì˜ 0ë‹¨ê³„ í‚¤ì›Œë“œ ì œê±°
                if MODE == "AUTO":
                    # ê¸°ì¡´ ë°ì´í„°ì—ì„œ 0ë‹¨ê³„ë‚˜ NaN ë‹¨ê³„ í‚¤ì›Œë“œ ì œê±°
                    if 'ë‹¨ê³„' in existing_df.columns:
                        existing_df = existing_df[(existing_df['ë‹¨ê³„'] > 0) & (existing_df['ë‹¨ê³„'].notna())]
                        print(f"ğŸ“ ê¸°ì¡´ íŒŒì¼ì—ì„œ 0ë‹¨ê³„ í‚¤ì›Œë“œ ì œê±° í›„: {len(existing_df)}ê°œ í‚¤ì›Œë“œ")
                
                # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
                # í‚¤ì›Œë“œê°€ ì¤‘ë³µë˜ë©´ ìƒˆ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸
                combined_df = pd.concat([existing_df, new_df], ignore_index=True)
                
                # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±° (ë§ˆì§€ë§‰ ë°ì´í„° ìœ ì§€)
                combined_df = combined_df.drop_duplicates(subset=['í‚¤ì›Œë“œ'], keep='last')
                
                print(f"ğŸ“Š ë°ì´í„° ë³‘í•© ì™„ë£Œ: ê¸°ì¡´ {len(existing_df)}ê°œ + ìƒˆë¡œ {len(new_data)}ê°œ = ì´ {len(combined_df)}ê°œ")
            else:
                combined_df = new_df
                print(f"ğŸ“Š ìƒˆ íŒŒì¼ ìƒì„±: {len(new_data)}ê°œ í‚¤ì›Œë“œ")
            
            # ê²½ìŸë„(ë¹„ìœ¨)ê°€ ë‚®ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            combined_df = combined_df.sort_values('ê²½ìŸë„', ascending=True)
            
            # ì—‘ì…€ íŒŒì¼ ì €ì¥
            combined_df.to_excel(filepath, index=False, engine='openpyxl')
            
            return filepath
            
        except Exception as e:
            raise Exception(f"ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")


# ==================== ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ====================

def main():
    """ë„¤ì´ë²„ ê´‘ê³  API + ê²€ìƒ‰ API í†µí•© í…ŒìŠ¤íŠ¸"""
    try:
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = NaverAdsClient()
        print("âœ… ë„¤ì´ë²„ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ í‘œì‹œ
        print(f"\nğŸ” í…ŒìŠ¤íŠ¸ í‚¤ì›Œë“œ: {', '.join(TEST_KEYWORDS)}")
        
        # í†µí•© ë¶„ì„ ì‹¤í–‰
        print("\nğŸ“Š í‚¤ì›Œë“œ í†µí•© ë¶„ì„ ì¤‘...")
        result = client.get_keyword_analysis()
        
        # ëª¨ë“œì— ë”°ë¥¸ í‚¤ì›Œë“œ í•„í„°ë§/ë¶„ë¥˜
        if MODE == "BASIC":
            # ê¸°ë³¸ëª¨ë“œ: ì„¤ì •ëœ ìŠ¤í…Œì´ì§€ ì¡°ê±´ì— ë§ëŠ” í‚¤ì›Œë“œë§Œ í•„í„°ë§
            print(f"\nğŸ” ê¸°ë³¸ëª¨ë“œ: ìŠ¤í…Œì´ì§€ {BLOG_STAGES} ì¡°ê±´ì— ë§ëŠ” í‚¤ì›Œë“œ í•„í„°ë§ ì¤‘...")
            filtered_result = client.filter_keywords_by_stage(result)
            result_to_save = filtered_result
        else:
            # ìë™ëª¨ë“œ: ëª¨ë“  í‚¤ì›Œë“œë¥¼ 1-5ë‹¨ê³„ë¡œ ìë™ ë¶„ë¥˜
            print(f"\nğŸ” ìë™ëª¨ë“œ: ëª¨ë“  í‚¤ì›Œë“œë¥¼ 1-5ë‹¨ê³„ë¡œ ìë™ ë¶„ë¥˜ ì¤‘...")
            filtered_result = client.filter_keywords_auto_mode(result)
            result_to_save = filtered_result
        
        print("\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
        print("=" * 130)
        print(f"{'í‚¤ì›Œë“œ':<15} {'PC ê²€ìƒ‰ëŸ‰':<10} {'ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰':<12} {'ì´ê²€ìƒ‰ëŸ‰':<10} {'ë¬¸ì„œëŸ‰':<12} {'ê²½ìŸë„':<10} {'ë‹¨ê³„':<5}")
        print("-" * 130)
        
        if filtered_result:
            for keyword, stats in filtered_result.items():
                stage = stats.get('stage', 0)
                stage_text = f"{stage}ë‹¨ê³„" if stage > 0 else "í•´ë‹¹ì—†ìŒ"
                print(f"ğŸ”‘ {keyword}")
                print(f"   PC ê²€ìƒ‰ëŸ‰: {stats['pc_search_volume']}")
                print(f"   ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰: {stats['mobile_search_volume']}")
                print(f"   ì´ê²€ìƒ‰ëŸ‰: {stats['total_search_volume']}")
                print(f"   ë¬¸ì„œëŸ‰: {stats['blog_count']}")
                print(f"   ê²½ìŸë„: {stats['competition_ratio']}")
                print(f"   ë‹¨ê³„: {stage_text}")
                print()
        else:
            if MODE == "BASIC":
                print("âŒ ì„¤ì •ëœ ìŠ¤í…Œì´ì§€ ì¡°ê±´ì— ë§ëŠ” í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print("âŒ 1-5ë‹¨ê³„ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì—‘ì…€ íŒŒì¼ ì €ì¥
        try:
            if MODE == "BASIC":
                filename = client.save_to_excel(result_to_save)
                print(f"\nğŸ’¾ í•„í„°ë§ëœ ê²°ê³¼ê°€ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
            else:
                filename = client.save_to_excel(result_to_save)
                print(f"\nğŸ’¾ ëª¨ë“  í‚¤ì›Œë“œê°€ ë‹¨ê³„ë³„ë¡œ ë¶„ë¥˜ë˜ì–´ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}")
        except Exception as e:
            print(f"âš ï¸ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        print("\nâœ… í‚¤ì›Œë“œ í†µí•© ë¶„ì„ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())